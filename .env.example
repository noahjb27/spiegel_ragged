# LLM API Settings
OPENAI_API_KEY=EXAMPLE_OPENAI_API_KEY
GEMINI_API_KEY=EXAMPLE_GEMINI_API_KEY

# HU LLM Settings - Multiple endpoints
HU_LLM1_API_URL=https://llm1-compute.cms.hu-berlin.de/v1/
HU_LLM3_API_URL=https://llm3-compute.cms.hu-berlin.de/v1/

# Remote ChromaDB Settings
CHROMA_DB_HOST=dighist.geschichte.hu-berlin.de
CHROMA_DB_PORT=8000
CHROMA_DB_SSL=true
CHROMA_DB_CACHE_DIR=./cache

ENFORCE_KEYWORDS=false

# Remote Ollama Embedding Settings
OLLAMA_MODEL_NAME=nomic-embed-text
OLLAMA_BASE_URL=https://dighist.geschichte.hu-berlin.de:11434

# Word Embedding Settings (für die Suche nach ähnlichen Wörtern)
WORD_EMBEDDING_MODEL_PATH=./models/fasttext_model_spiegel_corpus_neu_50epochs_2.model

# Verfügbare Chunk-Größen: 500, 2000 und 3000 verfügbar
DEFAULT_CHUNK_SIZE=3000
DEFAULT_CHUNK_OVERLAP_PERCENTAGE=10 

# Default model
DEFAULT_LLM_MODEL=hu-llm3  # Optionen: hu-llm1, hu-llm3, openai-gpt4o, gemini-pro

# Feature Flags
ENABLE_QUERY_REFINEMENT=false
ENABLE_CITATIONS=false

# Application Settings
DEBUG=true
LOG_LEVEL=INFO